from bs4 import BeautifulSoup
import re
import socket
import requests

from grab_main_and_splash import get_main_and_splash

class DrudgeBase(object):

    def fetch_page(self, url):
        ''' Fetches the html from a URL '''
        request = requests.get(url)
        html = request.text
        return BeautifulSoup(html, 'lxml')

class DayPage(DrudgeBase):
    ''' Signifies a date, in UTC time.
        Generated by day_page_list_generator()
    '''
    def __init__(self, day_page_url, drudge_date):
        self.url = day_page_url
        self.drudge_date = drudge_date

    def scrape_day_page(self):
        '''Goes through a day page and scrapes the links to the 
        individual drudge pages'''
        soup = self.fetch_page(self.url)
        url_front = 'http://www.drudgereportArchives.com/data/'
        all_urls = soup.find_all('a')
        ## add a BS functtion that gets all of the link text
        drudge_url_list = [{'url':url['href'], 
                            'time':url.text.encode('utf-8').strip(), 
                            'drudge_date':self.drudge_date} 
                            for url in all_urls if url['href'][0:41] == url_front]
                                
        drudge_url_list = [entry for entry in drudge_url_list if entry['time']!="^"]
        return [DrudgePage(self, 
                           drudge_page_data['url'], 
                           drudge_page_data['time'])
                           for drudge_page_data in drudge_url_list]
        
class DrudgePage(DrudgeBase):
    '''
        One method to scrape the drudge page and produce a list(?) of drudge link objects
    '''

    socket.setdefaulttimeout(5)
    
    def __init__(self, day_page_obj, url, time): 
        self.url = url
        self.time = time
        self.drudge_links = []
        self.link_count = None
        self.id = id(self)  

    def scrape(self):
        ''' scrape takes a url to an individual drudge page, and 
            scrapes every link.  '''        
        self.soup = self.fetch_page(self.url)
        main_links = get_main_and_splash()
        print "main links:"
        print main_links
        print
        raw_links = self.soup.find_all('a')
        for link in raw_links:
            # building the arguments for each Drudge Link object
            url = link['href']
            text = link.text.encode('utf-8')
            parent_id = self.id
            if link.text == main_links['splash']:
                splash = True
            else:
                splash = False
            if link.text in main_links['top']:
                top = True
            else:
                top = False
            self.drudge_links.append(DrudgeLink(url, text, parent_id, top, splash))
        return self.drudge_links

class DrudgeLink(object):
    def __init__(self, 
                 url, 
                 hed, 
                 parent_drudge_page_id,
                 is_top = False, 
                 is_splash = False, ):
        self.url = url
        self.hed = hed
        self.is_top = is_top
        self.is_splash = is_splash
        self.parent_drudge_page_id = parent_drudge_page_id

    def list_dump(self):
        return [self.url,
                self.hed,
                self.top,
                self.splash,
                self.parent_drudge_page_id
        ]